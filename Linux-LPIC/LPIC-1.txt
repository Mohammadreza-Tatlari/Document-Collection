### LPIC-1 ###
This note is dedicate for jodging down information about LPIC and fundamentals of Linux system.
WEBSITE: https://linux1st.com/archives.html
GIT REPO:https://github.com/jadijadi/lpic1book

### LPIC-1-005 - Hardware and Concepts ###
sysfs: its a folder/file that contains information about all hardware devices and kernels and other elements that our system has and it illustrate all of them to user and let the system use the information in order to function. all this information are located in kernerl
to have access:
cd /sys/ -> direct to sysfs folder

udev or /dev: are the file managers for systems which it means that they are sudoes and the real data is not there but if we find our hardware of device in this folder it means that we can do whatever we want because the root system has identified it. you can interact if udev files and write or read it directely and you can change data inside hard drive
also you can modify or customise devices via it. like configuration of recognizing a hard disk file.

D-bus (dbus) is a message bus system, a simple way for applications to talk to one another in addition to interprocess communication 

/proc direcotry (processes directory): is a folder which data of kernel setting and processes are located in there and its is placed inside the kernel not the processor and all processes have their unique ID and by directing them their activity can be monitored. but also it shows IRQs (interrupt request)
DMA (direct memory access, faster than I/O ports)
I/O ports ( locations in memory where CPU can talk with devices)
and network setting are all located in proc
Important: it is a sudo file system: which it means that it mock the result of file systems

how ever if you want to change some information directly it is essential to modify the /etc directory.


### LPIC-1-006 - Understanding of hardware functionality ###
some commands like ls
lsusb: listing for usb devices
lspci: for pci devices
lsblk: for block devices(devices that can be W/R like disks)
lshw: take a huge list from hardware

kernel loadable modules:
actually linux has most of the drives in built in condition so installing them are not required but for reducing the load balance and size of the Kernel all of the mare not loaded.the loadable files exist because all of them cannot be mounted.
consider the usage of drive which are commands and instructionfor example a webcam can interact with OS and how user can use it. however we have such thing as module. 
to inspect list of modules 
we can use: 
lsmod/ -> to list modules
rmmode -> to remove modules
modprobe -> to add a module (it is an easier way than insmod)
-f -> to switch and force action

fun thing:
Linux Kernel is looklike saying mashin benz (mashin = kernel , benz= linux)


### LPIC-1-007 - Boot procedure & Stages - each level and stages and introduction ###
the procedure of booting the system
1. the motherboard firmware does the POST processed (PowerOnSelfTest)
2.motherboard loads the bootloader for loading the OS on 
3.Bootloader loads the linux kernel based on its configs/commands
4.Kernel loads and prepares the system (root filesystem) and runs the initialization program
5.Init program start the service, other programs, .. (webserver, graphiccal interfaces , networking, ...) /init folder 
 
kernel is not responsible for starting all programs so it mandates init to handle those processes

note: firmware is not just responsible for loading the bootloader or grub. it loades whatever that is pointed to it. also bootloader is not obligated to just load the kernel it can load anything

we have 2 kind of firmware for bootloading 
1.BIOS (Basic Input Output System)
 which is older and much limited to one sector of the disk which can be called (MBR:master boot record) and needs a multi stage bootloader so
2.UEFI (Unified Extensible Firmware Interface):
is graphical and fancy it specifices a special disk partition for the bootloader called EFI System Partition(EPS)
ESP is a FAT and mounted in boot/efi and bootloader files have .efi suffixes/ extensions
you can check these files in /sys/firmware/efi


### LPIC-1-008 Boot Procedure & Stages - journal and logs ###
dmesg:
when we boot our system after the booatloading process the linux kernel gives a log about how its loading and booting. so it is possible to check it and analys the process if any problem occurs.
but this log happens behide a splash screen so to see it we can simply use ecs button or after the boot process we can use dmesg command to see the logs

conclusion: dmesg shows the kernel ring buffer

less /var/log/dmesg less shows the logs in page format also it is feasible to use cat
for fedora is in /var/log/boot.log

journalctl -> this command is the same as dmesg but categorizing and sorting is possible in it 
journalctl -b -> for boot journal
journalctl -u -> for all logs
journalctl -k -> for kernel logs which are happened before be written in hard disk

var/log/messages
the kernel is still logging its messages in dmesg due to buffer ring
in some systems, it might be aclled var/log/syslog
there are many other logs at /var/log

init(initializer) -> after the POST of motherboard, firmware, bootloader, and kerner the init is commenced via kernel to maintain and handle other procedures like checking the network and deamen which are bundled in subsystems, services and other deamens, but what is deamens? it is a way of process which application begin to work and listen and when a user call them they will response and make it plausbile to write condition for each logic. so deamens are applications running in background in order to be used.

there are different init systems:
-sysVinit; is base on Unix system V. it is now abrogated but some old system are still using it.
-systemd: is a new replacement for sysVinit. but in linux systems it was standarized that each program was dedicated to do one thing but in systemd some application do something in outstand actions. also many logs are not in text
-upstart: existed between 2014 to 2015 and was programmed by ubuntu and canonical team but it did not continue
we can use which init for each system to find out which kind of init we are using

ps -p 1 => shows the first process in system base on id which is 1
ps -p (process ID) => it shows the app that has the ID
pstree => to see the tree of processes (fun to checkout)
systemctl list-units --type devices => this command shows us list of unit in our system processor and in this case we want to just recieve devices type units
systemctl cat cup => for print the condition of for example cup.service (printing)

systemctl status sshd (for instance) => for checking the status of sshd 
systemctl enalbe sshd => enables sshd. the different between start and enable is that when we start the system the sshd is enabled so it will start alongside the system

systemctl is-running -> give you status on the way that system is working or if any services is degraded or upgraded
systemctl --failed -> shows the faild processes


### +LPIC-1-009 Runlevel - Targets - expression and definitions ###
runlevels: is like when the system is in live section or in what level the system can do certain things

systemctl status => gives all the information about all status of different process

commands that put the system in some special target
rescue: local file systems are mounted, there will be only root user 
emergency: only the root file system and in read only mode, no networking and only root 
reboot: it reboot the system
halt: stops all processes and halts CPU activities
poweroff: like halt but also sends an ACPI shutdown signal (no lights)

systemctl isolate emergency: set and isolate the target level in emergency target
we can check them in each target via: 
systemctl is-system-running command

this is how we can isolate each level target for ourselves to work with
runlevel => to see in which level we are 
we have 6 levels
to see each level and its configuration we can use 
/etc ls rc -> which contains all levels and their properties that system reads from them in each target level
for example after that if we write
init 6
then the system read fro rc.6 and reboot the system 

id:5:initdefault => this command used to exist in inittab(deprecrated) which was for setting the default init runlevel of system. thats why when system is restarted it returns to graphical interface 


### +LPIC-1-010 Runlevel - Targets - how to shutdown a system properly ###
when we are working with linux or unix system multiple users may be working on it but the admin somehow wants to shutdown the system/server so for doing such an action the admin should send a command that halt and stop processor in proper and step by step way. the procedure is like this -> the system sends for example a 15 code command to processes and the procedures stop there work programaticaly
or sends code 9 that shutdown the whole process suddenly

regular commands are sorted:
halt -> command halts the system and then stops the CPU
poweroff -> halts and shutdown the system via ACPI (Advanced Configuration and Power Interface)
reboot -> it reboots the system after shutdown

who -T shows the message condition of users in system
MOTD (message of the day)

### LPIC-1-011 FHS FileSystem Hierarchy Standard (came from Unix) ###
in linux stystem all direcotories after partition level are standardized in FHS system
the base and most importat files are:
bin: Essential command binaries 
boot: Static files of the boot loader
dev: Device files
etc: Host-specific system configuration ( which many conf files are there)
home: Home directory of the users
lib: Essential shared libaries and kernel modules
media: Mount point for removable media
mnt: Mount point for mounting a filesystem temporarily 
opt: Add-on application software packages (for example if want to install a package that is not part of the distro so it's better to be installed in opt directory)
root: Home directory of the root user 
sbin: Essential system Binaries ( more important commands. root only)
srv: Data for services provided by this system
tmp: Temporary files, sometimes purged on each boot
usr: Secondary hierarchy
var: Varibale Data (logs, ...)
for learning more about directories simply type ls or ls -ltrh in root directory to observe all directories
/ ls -ltrh

bin -> if ls is taken inside /bin folder, all regular commands will be shown


### LPIC-1-012 - Partitions ###
tip before top:
it is possible to dedicate a partition for instance 25GB for / directory (which means all the files) and 250MB for root and 950GB for /home directory. then if distro is needed to be change the only partition that will be overhauled will be the 25GB and the /home directory will be mounted on the new distro.

this part is about how much volume is dedicated to each part and why boot and /home are seperated from each other. Also what is swap and how the LVM (Logical Volume Management) really works. 
LVM: that we can connect multiple hardisks and build up a groupvirtual disk that functions as a single harddisk
swamp: Swamp is firstly invented in unix systems which makes a small part of hardisk to be dedicated to memory usage 
it is recommended to be parted in such order: memory + 2GB or memory * 2GB it depends on tpye of Hard Disk

gparted => is a command to initial the graphical interface of partition section

What is RAID: when same data is written on 2 seperated hard disk volumes


### LPIC-1-013 Bonus SWAP ###
Swapon -> to see the status of our swap part
parted dev/sda -> to see the all the partitions
command: 
top => shows status of processses
swapon => shows the location of swap if it exists
free -h => to show memory and swap storage
fdisk -l => to see all disk partitions and drives
 
what is the difference of Zram and diffult swap
Zram is new future of the linux that is developed in redhat and fedura distro(distribution) that it takes part of the RAM and zip the kernel of linux in it (zip means to compress the data of it). same as swap but from inside (expanding)

debian has partition that is dediacted to Swap
Ubuntu has file that is dedicated to Swap
Fedora36 has Zram that it compresses files and act like swap

Swap file: same as partitional Swap but it take a folder and use it as a swap Volume debian based OS uses this kind of swap structure

it is recommended to use Temp folder to use as swap but it is new inventon


### + important:  LPIC-001-014 GRUB and Bootloader installation part 1 GRUB legacy ### 
MBR (Master Boot Record): Legacy BIOS -> 0,0,1 (Clander 0, Side 0 , Sector 1) is the first location of Hard disk that is around 512 byte and contains information about boot loading. but in modern computer and more advanced boot loader the small part of the loader is placed in that location and computer reads from it and initiate the rest of boot loader in other locations. the memory that is being used Is called ?MBR?

GRUB (Grand Unified Bootloader): started to replace the older LILO. the first version (1) is GRUB legacy and started in 1999 the second version started in 2005 and is a complete rewrite of version 1. its menu based system which Kernerl or Chainloader is being selected to boot. it is also possible to edit the menu on the fly or give direct commands from a command line.
Grub configuration is possible via grub config file

UEFI uses stages to boot the system and these stages are like checking the security of OS and ...

definition of chainloading: when a boot loader, load another boot loader. for example when linux bootloader needs to start a windows system

### * important LPIC-001-015 ###
Installation and configuration of Boot and Boot loader part2 GRUB2

It is possible to change the configuration of GRUBs in linux systems but it depends on firmware and type of Bios or UEFI
to do so we can check out /boot/grub/grub.cfg file or with similar name.
in the file most of configuration and options are avialable and by changing the we can change the GRUB behaviour. it is possible to add new menuentry for it and config sda location and more changes.
all GRUB2 configurations are not placed inside a single file so for more conviniences grub-mkconfig file is created to implement changes to grub interfaces.
so in etc/default/grub or etc/grub.d there is a grub-mkconfig and you need to issue it and take an output form changes to it into another file:
grub2-mkconfig -o (or >) boot/grub2/grub.cfg

options of grub2:
menuentry: defines a new menueentry
set root: defines the root where /boot located
linux,linux16: defines the location of the linux kernel on BIOS systems
linuxefi: defines the Linux kernel on UEFI systems
initrd: defines the initramfs image for BIOS systems
initrdefi: defines the initramfs imafge for EUFI systems

sometimes when new menuentry is being created for linux system if the sda location does not come with proper place it will redirect you to a busybox environment which is a small linux system and can run some basic commands 


### LPIC-001-016 Managing Shared Libraries ###
ldd
ldconfig
/etc/ld.so.conf
LD LIBRARY PATH
when a programmer is developing a new app it is more convinient to use other libraries in  order to develop its program instead of reinventing the wheel. for example for window design qt lib may be require to be used.
2 ways of using library is common.
Linking:
Static: in static form the application is big and all the libs are included inside the app but its works independently. however, for example if a lib is 500mg and 2 similar app run simultaneously. then its like 1gb of that lib is being run. also if update comes for the library in 1 application all the others should be update manually. but it synced in dynamic usage
Dynamic: in dynamic the application is much smaller but it is dependent to the lib. however for instance when app wants to use the lib. lib is install on the machine and all application only need to call it. and when a the lib updates it applies to all application because they are all using the same lib from a same location.

libs are located in /etc or in user it depends on the applications. or programs
ldd (list dynamic dependencies)
the ldd command helps you find:
 . if a program is dynamically or statically linked.
 . what libraries
commands:
ldd (file/directory) => this command will show all the depending library that the software needs to be run
example : ldd user/lib/ldconfig

symbolic links: its the way that a file which a name is link and run another file which is the file that needs to be target. think of it as a file that leads to a file that do the work but with a different name

Dynamic library configs and cache: for instance files that are located  in /etc/ld.so.conf.d/*.conf will get updated to changed in updates or you want to change or add new configuration but also want to keep them after updates so simply it include your new file and keep them organized there.

command: 
ldconfig: creates a temporary cache file that contains all the information about libraries in /etc/ld.so.cache~

where OS finds dynamic libraries:
the system will search files in this order:
1. LD_LIBRARY_PATH environment variable
2. Programs PATH
3. /etc/ld.os.conf (which might load more files from /etc/ld.os.conf.d
4. /lib , /lib64 , /usr/lib ...


Bonus: hacking tip
ld-linux and how it execute a file that may not be able to be executed.
by readelf -W1 command can see which program requested as a interpreter
command:
readelf -W1 (filename)

###LPIC-001-017 use Debian Package Manager ###

package manager is the way linux distortions use the official repositories to install application instead of downloading an executable file and install it out of the standards.

dpkg: depackage does not work with repository. it gets a package and install it. but apt-get works with repository
in sources.list.d we add repository that we want to add out of the other repositories instead of adding them in sources.list. however, a new file should be created
why do we update apt?
apt is like a cache somewhere that hold all the address of program sources inside itself. so when we update the apt via apt-get update. it actually updates those links.
cache is placed inside /var/cache/apt
to install, sudo apt-get install (program name) is being used. so the program checks the source and then install it.
in /etc/apt/sources.list all the main source to find links and files are located
in /sources.list.d you can simply add your own links 

###LPIC-001-018 configuration and managing packages ###

in this section we more prone to survey the commands to control packages

installation:
apt-get install (program name) : to download the app
apt-get --simulate install (program name): to simulate the installation
apt-get install --download-only : to only download the app without installation
apt-get download (program name): to download only the for exmaple debian package

remove: 
apt-get remove (file name - program name): to remove the file or program
apt-get autoremove: it removes other dependencies that came by installation and have no usage

search:
because apt file is located inside the /var/cache repo so we use get-cache for searching
apt-cache search (program name): it shows all the packages that include the program name:
for instance: apt-cache search "tiny window" (tiny window is seperated so it is put inside cotation)

apt alone can contain all: apt search , apt install, apt remove ...

apt-get update: updates the apt-file in cache to check the repositories
apt-get upgrade: reads from update and checks whether system needs upgrade for application. so it reads from cache not online.

apt-get dist-upgrade: upgrade the distortions

Package information with dpkg
the underlying tool to work with .deb files is the dpkg. It us your to-go tool if you want to do manual action on a deb package. 
dpkg [OPTION] ACTION PACKAGE

some useful swiches:
-c or --contents: shows the contents of a package 
-C or --audit: search for broken installed packages and propose solutions
--configure:  reconfigure an installed package
-i or --install
-I or --info
-l or --list
-P or --Purge: uninstall the package but it removes it configuration with it.
purge can be used in apt-get as well.
and ...
apt-get install -f (fix broken): looks for dependencies that were required but haven't installed
apt-get dpkg -l: shows all installed dependencies
dpkg-reconfigure tzdata: uses debconf for reconfiguration of an app after it is being installed like installing and reconfiguring time zone of a timing app
apt info: shows the information of a package 

###LPIC-001-019 Other package managers like YUM , Zypper and RPM###

RPM(RedHat Package Manager), YUM (YellowDog Update Manager) are used by Fedora, RedHat, RHEL, CentOS and RockOS to manage packages

In fedora recent package manager yum.conf is not present any more because this distro is using DNF package manager so yum commands are being translated to DNF commands

yum commands:
update: update the repositories and update the names packages, or all if nothing is named - it can update and upgrade simultanously
install: install a package
reinstall: reinstall a package
list: show a list of all packages or can show installed packages by --installed switch
info (important): it shows information about packages
remove: removes an installed package
search: search the repository packages
provides: check which packages provies an specific file
upgrade: upgrade packages and removes the obsolete ones
localinstall: install from a local rpm file
localupdate: updates from a local file
deplist (package name): shows the dependency list of a package
groupinstall:
histroy: shows all the history of using the yum

wildcards also can be used for package update
yum update 'cal*'

yum download --resolve (package name): also download the packages will all dependencies

###LPIC-001-020 RPM packages in Red hat distortions such as Fedora ###

RPM command can run actions on inidividual RPM files.
command
rpm ACTION [OPTION] rpm_file.rpm

rpm2cpio
cpio is an archive format. you can use the rpm2cpio command to conver rpm files to cpio and then use cpio tool to extract them

the SUSE Linux and openSUSE uses Zypp as their package manager engine. you can use YAST or Zypper tool to communicate with it
command:
zypper [options] or [swtiches]

https://linux1st.com/1025-use-rpm-and-yum-package-management.html


### LPIC-001- Module 102.6 Linux as a Guest Virtual Machine ###
Virtual machines are simulate computer that are created on top of an OS.
to run a virtual machine we need a hypervisor (or virtual machine manager) like virtual box that we can simply create our own VM.

for running hypervisor on a OS first should be checked whether the OS can support the hypervisor. for instance 64bit operating system are more likely to be able to support it and should check for vmx (for intel CPUs) or svm (for AMD CPUs) in /proc/cpuinfo to find out.

There are two types of Hypervisor
hypervisor 1: like hyper-V or KVM and Xen that need to be installed on hardware and then to mange OS.
Hypervisor 2: like VMware and VirtualBox that are able to be installed on OS and run other Operating Systems inside of them

Cloning: can be used in hypervisor to clone an exact operating system with same configuration over and over
Open Virtualization Format (OVF): can transfer machines between hypervisors. it acts like template as well

when a virtual system is being cloned or copied it should be consider that some specific attributes should not be similar if it is NOT going to be used in isolated environment.
Host Name, NIC MAC Address (Network Ip Controller) , NIC IP (if not using DHCP) , Machine ID (delete the /etc/machine-id and var/lib/dbus/machine-id and run dbus-uuidgen --enusre. these two files may have soft links to each other)
encryption Keys like SSH fingerprints and PGP keys
HDD UUIDs
Any other UUIDs on the system

Containers vs Virtual Machines:
as it was discussed virtual Machine handles the whole guest Os and prepare libs and bins for specific app and then runs it. os takes all the OS files and some other files that can be counted as redundencies.
but Containers only keep the libs/bins of an app and only app can see those libs and if the container need any file from OS it may take it directly from the OS which is being run on it.


###LPIC-003-1 working in command line -variables - SHELLS ###

uname give you data about the system. Swtiches:
-s: prints the kernel name it is the default
-n: prints the node name or the host name
-r: print the release of the kernel
-v: print the version of kernel
-m: prints the machines hardware
-o: prints the operating system name
-a: all the information

man => use it for get the manual of each command
in manual or man command it is possible to man the man and it will give guidance about the man each section thus it can help to find and learn more about all the system
for instance
man passwd => will show manual of passwd execution command instruction but
man 5 passwd => will show the file format of it

for using the special characters ( * ? [ ] ' " \ $ ; ( ) | ^ < > ) in command or if want to print them we need to escape them by \ (backslash)
for example:
echo \* => to print *
echo \$NAME => to print $NAME not the variable one

for using the escape method for example as \n new line we need to active it by typing 
echo -e "\n\n"  (check out the manual of echo)
bash histories can be save inside the .bash_history or history. it can be used for security inssurance 

## PART TO OF THE FOLLOWING TOPIC ##
variables are like some names that hold values inside themselves.
such as this example:
NAME=SOMETHING (remember if you are writing this in shell, should know that shell is very sensitive thats why we didn't make any space between something and NAME if you want to use spacing then should put the word in double quotation "")

then with echo $NAME (we use $ to say that we want to echo NAME variable not just word NAME) we return that SOMETHING word

also some environment variables are present in system
by typing 
" env or set " inside the terminal we can see all of them
check out all other stuff in variable like PS1 and ... in the book

commands:
whereis ping: shows all the executable files that are related to ping
which ping: shows the file that is being executed as default

environemnt name and functions:
USER: the name of the logged-in user
PATH: list of directories to search for commands, colon separated
EDITOR: default editor
HISTFILE: where bash should save its histroy (normally ,bash_history)
PS1 (fun): The Prompt
UID: the numeric user id of the logged-in user
HOME: the users' home directory
PWD: current working directory
SHELL: the name of the shell
$: the process id or PID of the running bash shell or process
PPID: the process id of the process that started this process
?: the exit code of the last command

fun practice for promt: you can simple change the promp style by changing the PS1
for instance:
echo $PS1 will show the default structure of the ps1. but by typing PS1='->' turn the whole command indicator to the ->

export $NAME: export let the variable to be used in other level of programing or processes and not just in the level that is defined

PATH variable: bash or shell repository check whenever a command is set and its not an internal command.
by typing echo $PATH all path of commands can be seen to add a new location for command simply can export new one:
export PATH = $PATH:/desiredlocation/
shell does not execute any variable in dir that is been. but windows does. because it has securities issues. for example simply hackers can abuse it by executing that variable directly form that directory. so ./ is used like ./ping

useful hotkeys for .bash_history
ctrl+R: for reverse search in command
!!: run the last command
!7: run command number 7
use cautiously by history command
history: shows the command history

if you want to clear history:
HISTSIZE=0

###LPIC-001-024- GNU based Filter Streaming 1/4 ###
Streams: in UNIX world a lot of data is in Text format it means unlike for instance word office that some text can only be read by the word app and all the data is not in text format, all the data is editable and readable in a text format. so streams are like ls cat or other commands that can be used to edit input and output

command
cat: is for concatenating files and have options
zcat: can open a gz file can print it on standard output
less: can paginate the file or long text
od: do the octal dump of a file it can also show the structure of file and it can be used to get more in depth detail about the file
od -a or od -c


notes:
ctrl+D end the app properly
ctrl+C exit forcefully

modern programming environments and shells used three different standards for I/O streams:
stdin: is the standard input streams,which provides input for command
stdout: is the stadard output stream, to display output from command
stderr: standard to display error stream

veiw commands: like cat can help to see any files streams and data. also cat has some relatives too :) check the LPIC book
less: is for long data to make that data in pagination format.
shift + G goes to the end of list or data. if want to check any line simply that line of code can be written in less (:1000) then shift+G to see that line.
with / anything. like /chesh /name
n for next search result
?name to search backward

od: this command do the octalDump (showing in base 8)
like od /filename
-t in od tells what format to print -t a or -t c (summerized -c , -a)


### LPIC-001-025 stream filtering - spliting 2/4 ###
commands:
split: this command can split a file in to different way and it can be declared by using its options (use man for further instruction)
for instance:
split -l 2 file.txt => it split the file.txt base on 2 line and export them in different files

cat filenames * > (desired-file) => it can simple attach all the files together and export them to desire-file name as a single file

head (filename): shows the first lines of a file
tail (filename): shows the last line sof a file

cut: print selected parts of lines for each FILE to standard output
for instance:
cut -f1,3,5-8 -d: filename.txt
 
important by tail -f which f means follow we can see the end of each file and if any thing new happens it will show it. it is very common to use it for reading logs from an ongoing app

### LPIC-001-026 stream filtering - sorting 3/4 ###
commands:
nl (filename): shows the line numbers of a file
sort: sorts the file conent (sort -n filename: sorts by number)
uniq: works only on sorted files and ingore repeated content
uniq also can count number of repeated works by -c option
paste: paste contents of a file to another
tr: translates indicated file to something that is indicated as well. it works like replacing
instance: cat filename | tr '1234567' '۱۲۳۴۵۶۷': it replace these numbers in whole file and replace it with persian one

sed: stream editor for filtering and transfroming text
search "sed one-liner" for handy commands in sed  

sort and uniq are very useful for sorting and check uniq words in data importat to chech man of each command.
sort LPIC.text | uniq => it sort the LPIC.text and then send it to be checked by uniq
tr - paste are useful to boot
sed is one of the most powerful stream editors check out sed one-liner for more information.
for example: sed 's/USD/USDT/' logs.txt it replaces USD with USDT in log file
also s/a/b/g (the g in the end do the switch globaly) becuase sed changes line by line

### LPIC-001-027 Stream filtering - module 103.2 4/4 data hash and analysic data ###
wc -> word counter and paragraph counter or number of lines as well it depends on given option
for instance: wc filename
if you put - instead of filename the data will be replaced  from the pipe (stdin)
wc -l data | cat data - data

hashing:
A hash function is any function that can be used to map data of arbitrary size to fixed-size values. There are different hashes and we use them for different purposes. For example, a site may hash your password in its database to keep it secure (and check the hash of provided password with a hash it already has in DB during logins) a site may provide the hash of a file so you can be sure that you've downloaded the correct file...
type of hashing.
md5sum is the oldest one 
sha256sum
sha512sum
hash is really important for security and double checking the file validity

### LPIC-001-028 Perform Basic File Managment - Important 1/3 ###

wild cards and globbing 
files globbing is shell capability which let's you declare things like: All files - everything  which starts with A - all files with 3 letter names which end in A or B...

to do so you need to know about these characters:
* means any string 
? means any single character
[ABC] matches A ,B and C
[a-k] matches a,b,c ... k (both lower-case and capital)
[0-9a-z] matches all digits and numbers 
[!x] means NOT x

ls with absolute path or certain commands
ls -R : recursive listing it list the inner of repositories as well
ls -ltrh: human readable listing (-r stands for reverse)

cp : it copies files 
cp -rv : copy recursively and verbose 
cp -rv * /etc/: copy everything to /etc/ dir

mv: is rename and also move. however moving and renaming is almost similar in memory usage.
mv directory/* .: move everything from directory to where I am.
rm -r: for removing recursively for repository

mkdir: to make directory
rmdir: to remove directory
mkdir -p folder/newfolder/newerfolder: to make directory recursively


### LPIC-001-029 File Management Commands 2 ###

touch: is a way to change time stamp but if that file does not exist then it will make a new one.
touch -r: referencefile to filname: it will make the reference of that file's time to the file we want to
practical use for -r: for instance changing the file's time to be redeployed by a processor

file: checks the type of the file and in itself (very useful)

dd: is similar to copy but its more powerful and has greater features and accessibilities. it also contains of and if(input file) and of(output file) can be useful for changing data of a file
it can also convert and format a file (manual should be checked)
for instance: 
dd if=/var/zero of=zeros count=100 (record) bs=1 (block size)
practical use:
sudo dd if=ubuntu.iso of=/dev/sdc bs=2048 => burn an iso file to a flash disk 

find: let you search for a file 
find . -iname "name that we are looking" => it searchs all for files that have desired name inside them
find . -iname "*png" => looks for png files 
find . -type d => find all directory type results
find . -size 100c => looks for all images with 100 character images
find . -empty or -size 0b => looks for all empty files

swtiches for find that are related to time changes
-amin +10 => shows files that are changed more than 10 minutes before
-cmin -1 => shows files that are changed less than 1 day ago
instance:
find . -type f -mmin -30 -ls => shows files that are changed less than 30min ago and then lists them
find . -name "*.htm" -exec mv '{}' '{}l' \; => it will find all .htm files and rename them to html by adding a l to the end of the file exntension name

### LPIC-001-030 File Management compressing and zipping files  ###
in linux base system compressing and gathering files together obey different algorithms and each of them have their own programms.

gzip:
is one of the common ways for compressing files. but remember if the file is so small after compressing the file may increase in size due to incoding and meta datas. so zipping and compressing are reliable in order to be used for large data.
gunzip: is for unzipping the zipped file

other algorithms for compressing and zipping. sometime they are links to each other
bzip2, bunzip2
xz , unxz
 
tar:
TapeArchive or tar is the most common archiving tool. It automatically creates an archive file from a directroy and all its subdirs. it actually attachs files together

switches of tar is little bit different because they can work without hyphen(-)
example:
tar cf (desired name for tarfile) (filename) (filename) ...
tar cf myfiles.tar info.txt task.txt my-tasks

tar xf (tar filename): to extract tar file

tar cfzv compressedAndArchived.gz *
this command create gz file with tar and zip it with (z) command and is verbose 

cpio:
another legacy way of archiving files together
keep in my that cpio does not look inside the folders. So mostly we use it with find
example:
find . -name "*" | cpio -o > myarchivefind.cpio


### LPIC-001-031 Streams, pipes and redirects ###
redirecting standard IO
as it was mentioned before about stdin ,stdout and stderr which are standard input output and error. it is also possilbe to redirect them and choose which device or source become input or output. for example a monitor is an output and keyboard is a input but a program or a file also can be an input or an output too.
stdin = 0 code
stdout = 1 code >

for instance:
ls > report.txt => this command will redirect ls output into report.txt

note that 0, 1 & 2 numbering. the are called file descriptors. if you want to redirect the error, you can do 2> and only the error will be redirected

redirection use commands:
> redirect STDOUT to a file; overwrite if exists
>> redirect stdout to a file; append if exists
2> redirect stderr to a file; overwrite if exist
2>> redirecrt stderr to a file and append if exists
&> redirect both STDOUT and STDERR; overwrite if exsit
&>>redirect both stdout and stderr and append if exists
< redirect STDIN from a file
<> redirect STDIN from the file and send the STDOUT to it

example:
ls j* x* >> output 2> errors

it is also possible to use &1 and &2 &0 to refer to the target of STDOUT, STDERR and STDIN in this case ls > file1 2>&1 means redirect output to file1 and output stderr to the same place as stdout

/dev/null = works like a black hole (kernel gets it and release it to nowhere) and can be used for uninterested stdout

Here-Documents is also a useful input that can be used for redirecting inputs. checkout the original LPICDOC


### LPIC-001-032 streams pipes and redirections 2/2 ###

Pipes: with Pipe (|) you can redirect STDOUT , STDIN and STDERR between multiple commands all on one command line.
when you do command1 | command2; command1 is executed but its STDOUT is redirected as STDIN into the COMMAND2
example: ls -1 | wc -
another instance:
cut -f1 -d, filename.txt | sed -e 's/ //g' | sort | uniq -c

xargs: this utility read space, tabs ,newline and end-of-file delimited strings from the standard input and executes the provided utility with the strings as arguments.

example ls | echo -I HERE these are files: HERE. Finish

tee: 
the tee utility save the file and also send the data to STDOUT to demonstrate the procedure or saved files.
it can be useful for monitoring the work flow or data management.
example: ls -1 | tee allfiles
the command above ls the files and sent the output to a allfiles also show the result in terminal


### LPIC-001-033 Process Management Create Monitor and Kill Processes. ###

when  a process is run by shell its impossible to run another app with that shell until that process is stopped paused or killed

some commands for managing processes.

ctrl + z: can stop a process in terminal
fg : start the default chosen process (ForeGround)
jobs: show all processes that are being stopped
fg %(number of process): to start that specific process in foreground
bg : starts the process but in background and only can be seen by jobs
and to stop or ctl+C them we need to send them to fg with fg command
& : when we add & in the end of for example xeyes, shell sends it to bg
jobs -l: show the process id (PID) 
PPID: Parent Process ID
nohup: nohup lets you  run your command even after terminal bein closed.
also the output of the process will be written in nohup.out file
and by command tail -f nohup.out we can see the tail of that file (useful for ping)
example : nohup script.sh > mynohub.out 2> &1 &

Kill: is the way to terminate the processes. but this command has some important signals that can be read by man kill and its manual.
some important signals:
1: it means hub. it sends signal that your PPID is closed so be end
15: it stands for TERM. Terminate the processes
9: it stands for KILL: it kills the processes forcefully
SUDO: use sudo to terminate others processes as well. it can be useful in servers or SSH commands
Killall (processes name): it kills and send -15 signal to all process names 
pkill (xe): is for killing the name files that have xe inside of them


### LPIC-001-034 Process Management ###
ps: is to demonstrate the process that are running on the shell
but if all processes are wanted to be watched,
ps -e: shows all process in system
ps -ef: shows the full data
ps -aux | head: shows more data
ps -ef | head => to see head of processes

pgrep => it is equivalent of ps -e | grep "process name"

sometimes we monitor the system for such use we can use:
top: it mintors the processes

load average in top, what does it mean?
the  0 , 0 , 0 stand for 1min , 5min , 15min and it means that how many process are in queue to be processed and if it becomes more that the CPU threads it means there is a problem with process load.
load means the number of processes queued to be run

note: if number of loads are more than number of cores it means that something is wrong
top commands:
shift + m => in top, shift+m shows memory and process usage of each process
c => shows the full execution path and full information
in top panel we can use keys such as m for manual or k for killing

commands:
free -h : shows the memory accecibility 
uptime: is to see the uptime of the system
uptime -p: pretty , uptime -s: since

watch: is the way to monitor a process by giving it a command like watch uptime
watch df -h
watch uptime
watch  df -h | grep sda1

du -hs: disk usage 


### LPIC-001-035 Process Management - MutliPlexer - Tmux - Screen ###
Screen is like shell that help to manage multi processes it is much easier than nohup and multi screens can be used
for using screen and its command usually:
ctrl + A is pressed and then the option can be selected 
D: for example D means to detach the process
ctrl + D => terminate the screen
-r: it means to reattach the process by the id 
screen -ls: shows the list of processes
ctrl+A, | : it splits the screen
ctrl+A, tap: change the tap (remember to ctrl+A before)
after ctrl+A , Tab you can say ctrl+A, C to use the splitted screen

Tmux: is another tool like screen but it is more advance
ctrl+B: is its shortcut for using comands instead of ctrl+A in screen
shift + %: it splits the screen
shift + ": splits vertically 
tmux -ls: to see all tmux screens
ctrl+B, C => it creates new screen
ctrl+B , O or ; => it will switch to different tabs
tmux attach -t (tmux screen number) => switches to that screen
ctrl+B , (tmux number) => it will switch to desired screen for watching processes
tmux is very important check out jadi full course about it 
multiplexers lets you do multiple monitoring or multiple screening for convinient use.
cause it is based on terminal so it can be run on every system that has CLI

### LPIC-001-036 Modify Process Execution Priorities ###
nice: The NI column in Top shows how nice this process is. The nicer the process, the less CPU it asks. The nice values can be from -20 to 19. 

ps -l | head can also show niceness

Process state Codes ( can be seen in manual of ps):
zombie processes are like parent process that has run a child process but still did not read the value of the child's return value. so its ended but still its value is present in OS memory. nice = -20 is ANGRY and gets more priority for CPU and RAM while a process with nice = 19 is SUPER NICE and lets other processes use the resources before it.

renice: to rearrange the niceness of a process
default nice is 0
nice -n ([-20,19]) command => will run the command with that niceness value
example: renice -n 5 (PID)
r in top command can do the same for renice

using nice can be efficient for times that we are taking backup from files or doing processes that do not have top priority it helps resources to be well used. thus for example taking backup will not decrease midnight efficiencies :)

### LPIC-001-037 Search Text files using Regular expressions - Regex - searching with grep ###

regex: is one of the ways to filter out text and find out any specific items that is clarified.
it is called regular expression and is super useful for extracting data or modifying in large scale
https://regex101.com/
https://regexone.com/

for example: 
^.{2,5},(.*@): ^ means that in the first of each line. . means that anything and {2,5} means to be between 2 to 5 words. () it means more emphasize on that.
$ means the end of the line
regex is a vast topic that can be discussed but some useful expression are:
The * that means repeating the previous character for 0 to more times {0,...}
the + means repeating the previous character for 1 or more times {1,...}
the ? means zero or one repeats {0,1}
| : it is fore or like a|b
[^ ] (negation): everything but... for example ^session => everything but session
\d => for finding all digits

note
regex is case sensitive 

Range: [: :]
[:alnum:]
[:blank:]
[:digit:]
https://www.youtube.com/watch?v=Pm7baDkoeiE&ab_channel=JadiMirmirani

grep is also another useful command for searching
grep also has switches 
-c: just show the count
-v: reverse the search ( for example looking for things that are not similar)
-n: show line numbers
-l: show only file names
-i: case sensitive
-r: read all files under each directory recursively
instance
grep -rl 192.168 /etc => shows all files that contain 192.168
extended grep: egrep is a way to use regex with grep 

by typing -r in sed we can add regex to it for instance:
sed -r "s/(Z|R|J)/starts with ZRJ/" file.txt

Fixed grep:fgrep if you need to search for exact string

pymol
clc main or genomics work 
bench 23 
excel 
word office


### LPIC-001-037 vim SUPER IMPORTANT ###
vi
vim is vi Imporved
vim has two mode: command and insert
insert (i) is when we type script and command is when we use keys to navigate, copy and move between lines

in VIm we have some hotkeys
i: for inserting and insert mode
a: for appending the text in that current line. good for end of lines
r: is for replace the current position of cursor
o (for bottom) O(for top): it opens line
x: for deleting the current from left to right
X: same as x bur reverse
dd: for cutting
Pp: for pasting 
cw: copy the word
dw: cut the word
xp: for changing to words position beside eachother
use these keys in command form for:
h: left
l: right
j: down:
k: up 
w: next word on current line
e: next end of the word on current line
can use digits for frequent of commands
3 e: jumps 3 time to next word
4 k: it means 4 times jump 
ctrl+f: scroll one page forward
ctrl+b: scroll one page backward
G:(go) without number, it will jump to the end & 10G jump to line 10
H: 2H 2 line from top of the page high
L: 2L 2 line from bottom of the page low

searching:
/: for searching
n: for next
?: for searching backward
u: undo

:q for quiting but :q! is for overriding the quit
:qw : quite and write
:w [path]: write in a specific path


### LPIC-001-039 Creating Partions and filesystems with F-disk G-disk Parted ###

to observe the disks:
fdisk (for bios based systems): 
fdisk /dev/sdb -l (l will list information)
lsblk => to list block devices
note in commands:
in fdisk menu after v( verification)
w will write the disk partition modification

blocked devices: is a nonvolatile mass storage devices that information can be accessed in any order, like hard disks, USB memories, floppy disks, and CD-ROMs.

in older computers that have BIOS that use MBR (master boot record) we use f-disk for managing the blocked  devices and disk
but in UEFI(unified extended firmware inteface) we use GPT (GUID Partition Table) and we use G-disk
gdisk for UEFI
parted and gparted(graphical parted): are used for more advanced disk parting

### LPIC-001-040 partions and disk managment 2/2 ###

file formats are the way that computer write down data
ext (extended file systems)
fat (file allocation table)

ext2:second extended filesystem was developed to address shortcomings in the older Unix/Minix filesystem used in early versions of Linux. It has been used extensively on Linux for many years. There is no journaling in ext2, and it has largely been replaced by ext3 and more recently ext4.

journaling: its a way that writing on disk works. it checks the journal list where it has been writing data or if the data that is for example interupted is completed or its incomplete thus it will rewrite it or keep up the rest of procedure

ext3:ext2 + journaling, max file size is 2TB and max filesystem size is 16TB

ext4:current version of ext, max file size is 16TB and max filesystem size is 1EB (1000*1000TB)

XFS:journaling, caches to RAM, great for uninterruptible power supplies, Max file and filesystem size is 8EB

swap:Swap is used when the system needs to use more ram than what is has. It's like an extra ram on disk

VFAT:FAT32, no journaling, good for data exchange with windows, does not understand permissions and symbolic links

exFAT:Extended FAT. A newer version of FAT which is used mainly for extended device which should work on all machines; like USB disks

btrfs:A new high performance file system. Max file and filesize is 16 EB. Has its own form of RAID and LVM and build-in snapshots and fault tolerance and data compression on the fly.
btrfs is one of the most popular file formats

be careful when formating a file thats why some computers and OS do not recognize other disk or blocked devices

creating filesystem
commands:
mkfs => it makes a file system with desired type (for example after sdb and sda1 are created)
mksf -t ext3 /dev/sdb1

note:
-t in mkfs actually calls mksf relevant commands
ls /sbin/mkfs* => will list all mkfs relatives

mkswap => it makes swap format for our partition 
sudo fdisk /dev/sdb -l
sudo mkswap /dev/sdb2 (if the sdb2 is the swap formated disk)

system uses UUID for partition not the sdb or sda cause partitions can be transported into other OS systems or computers.

blkid /dev/sdb => will show the UUID of the disk

### LPIC-001-041 Maintain the integrity of filesystems - checking filesystems ###
du: disk usage
df: disk free

this two are used for checking the condition of disk
inodes: is the way that contain information about disk and spaces of blocked devices such as the owner and access and .... inodes are like the index page of a book that can be filled and hold information about each chapter
ext has this problem that the index page can be filled but we still have empty pages to write but its so rare to happen

df -i -h =>shows the inode of disk free
df -TH => print its type and make it human readable 
du
du -h --max-depth 1 => this command shows the depth of 1 of where the user is and shows the usage of data

for instance to show users disk usage:
du /home -h --max-depth 1
 
### LPIC-001-042 changing and checking filesystem ###
sometime datas can be damaged or not be completed due to inconcistency and disorder like power outage or due to bad sectors in disk. for solving this problems we can use fsck
fsck (file system check): when a disk is going to be check by fsck, that disk should not be mounted.

cat /etc/fstab : is the location where system read where should each partion be mounted and gives information.

*remember:
you should format a file to for example ext3 or ... in order to be able to use fsck or tune2fs
steps:
fdisk.(format) /dev/(targeted sdb) => format desired file to selected format
similar to mkfs, fsck has its own sub commands like e2fsck or fsck.ext3
fsck -A: checks the fstab and set for trouble shooting
fsck -N: similate the process of file checking
fsck -i: makes checking interaction
fsck -y: assume yes for all integration
fsck -a: makes everything automatic

mk2efs: it also create ext2, ext3 or ext4 filesystem

tune2fs -l: give much more information about a disk 
instance:

debugfs: for changing and debugging data
superblock: writes like raid for backup or restoring

xfs_fsr: file system reorganizer: it is similar to defrag the hard
xfs_info: gives information
 

### LPIC-001-043 Mounting and unMounting filesystems ###

when a new blocked devices like a USB is connected to the Unix system device it does not indicate it as same as windows like C: D: E: it send it to the tree structure of Unix system such as /mnt or /media

mount (blocked device) (repository) => it will mount the blocked devices where it is indicated
instance:
mkdir /tmp/username
mount /dev/sdb3 /tmp/username => this will mount sdb3 to /tmp/username
therefore all data in filesystem of sdb3 will be shown in /tmp/username

(man umount) -o will show options
umount (path): it will unmount
instance:
umount /dev/sdb3

mount => it will show all mounted drivers

also swapon and swapoff have there own commands

### LPIC-001-044 Mounting and UUID and fstab
UUID is used to make a disk to be unique universally and it can be mounted on any other devices thus its name will be changed but it does not affect on functionality

command:
blkid => it will read UUIDs directly
lsblk -o +UUID => It will show all UUID of disks
mount UUID=(uuid) /media => it will mount the disk with relevant UUID to /media
umount /media => to unmount what is mounted
disk can be mounted by its uuid instead of its name 

fstab: its a file that modify which file should be mounted and not be mounted
cat /etc/fstab
we can simply add script to it in order to mount or unmount a disk with special options for example
/dev/sdb2 /media/mydisk ext4 rw,user 0 0 => by adding this script to it will will mount /dev/sdb2 to media/mydisk in ext4 format with read and write and even normal user can mount or unmount it. 0 0 have two other options 1 which it means have backup from it and 2 which it means what modification should disks have 

systemd has its own .mount file in which indicate filesystem mount point controlled and supervised by systemd

### LPIC-001-046 Manage File Premission and Ownership (Users, Group) ###
in linux permissions can be categorize in groups and individual users thus we use these terms in order to give privileges
commands:
whoami => shows the user name that is currently in use
groups => shows groups that the user is involed
id => shows the user ID, and group ID and other information

this information come from:
cat /etc/passwd
cat /etc/group

each file also has its own information about user and group permissions of it in ls -ltrh can be seen
in -ltrh you may see somethi like this:
drwxr-xr-x => it is seperated in 4 parts 1.d 2.rwx 3.r-x 4.r-x
1. it means it is a directory. if it is - it means its a file
2. owner privileges
3. group privileges
4. other privileges
r: read, w:write, x: execute, d: directory, l: link , -: file


### LPIC-001-047 Changing permission, unmask ###

command:
chmod => is used for changing permission accesss 
2 ways of giving permission
with symbolic or octal
rwx = 7
rw- = 6
r-x = 5
r-- = 4
-wx = 3
-w- = 2
--x = 1
--- = 0

trick: 0 means nothing 1 means execute 2 means write and 4 means read => sum them up and find the best privilege :)

for example:
777 => -rwxrwxrwx
660 => rw-rw----
chmod 775 -v bash.src => change to rwxrwxr-x 
chmod +x  bash.src => add executable permission
chmod u+x bash.src => give user executable permission
chmod g+rw,u+rwx,o+rx => multiple permission giving
chmod g-rw,o-x => to remove permission

be careful when changing permission cause it can be remotely abused!

chown => change the owner
chown username:groupname (file) => for changing file ownership
chgrp (groupname) (file) => change group permission
newgrp (groupname) => to create new group

access mode
ls -ltrh /usr/bin/passwd => simply can use which passwd or whereis passwd to find it
-rwsr-xr-x => s stands for SUID(set uid)
set UID means the usr that runs the command will only access it by the user specific previleges and will happen for that user not for anyone
actually it runs with user access level and also it has root access as the user that is running it
access modes:
suid = 4000 u+s -s
guid = 2000 g+s -s
sticky = 1000 +t -t
sticky means only the declared user can delete it. example => drwxrwxrwt

umask: to example it we should first consider why the default permission access is -rw-rw-r--.
with normal user whe we use command umask it returns 0002 (with sticky) the default of permission giving is 666 so when 666 - 002 it returns 664 and it stand for -rw-rw-r--.
thus if umask changes the octal and therfore the permission changes as well.
umask can be changed.

command:
umask 0066 => it will change umask from 0002 to 0066 so it takes away many permissions

### LPIC-001-048 Create and change hard and symbolic links ###

links act like shortcuts to access a file from another place inside our storage it is called hard link.
hardlink acts as another entry to the program.
soft link is 

command:
ln (realfile) (hardlink) => ln make a link from firstfile to hardlink file
ln -s (realfile) (softlink) => it creates softlink from realfile and save it as softlink file 
ls -i => shows inode of files (can be used to see if inodes indicate to same location)

note: actually soft link is just an indicator to the file thus it can have different inode and even size
by using ls -l these links can be identified

command:
unlink or rm => removes the link

due to property of soft link and hard link, when file is removed hardlink still exists but softlink breaks

hardlink cannot link a directory. also hardlink cannot link through two different filesystem. but softlink can

practicall instance:
cd /usr/bin
sudo ln -s python3 python => thus whenever python is run the python3 will be run and python3 shortcuts to python3.10 for instance


### LPIC-001-049 FHS (File Hierarchy System) in UNIX and Linux ###
more advanced topic of LPIC-1-011
note:
commands:
cd /var/log , ls -ltrh => it will show all recently changed files so we can find out what has happenede

commands:
which, whereis, type => commands to find out where program and file are located and get more data
which -a ping => show all ping files
whatis ping => reads first line of manual of ping and prints it

find (filename) => helps to find a file
-user and -group: specifies user or group
-matdepth :  how deep should search directories

find . ! -user jack => it will search users but do NOT include jack user in query
find /etc -iname "includedname"

but find is slow thus we can use other commands like locate 
locate => it runs updatedb every 24h and then looks for files inside that database to improve performance. updatedb search through system and gather information about location of files
in debian it is called plocate
its configuration files are located in /etc/updatedb.conf or /etc/sysconfig/locate

### LPIC-001-050 Customize use the shell environment ###
environment variables are used in shell to hold specific values

commands:
env => it prints environment variables in system 
set => allows you to change the value of shell options or to display names and values it is more detailed. also set has its own options
unset => it is used to unset a variable
unset NAME => it will unset the NAME variable ($NAME)

export:
because processes like ping works as subprocess in bash, when a variable is set in bash it only works in that environment so when a new bash is run the new subprocesses only obey the bash that is above them (thats why bash can be run inside itself). thus when a variable is declared in bash. it won't be accessible inside another bash. therefore we export variables.
for example:
export NAME=Mohammadreza
$NAME will be exported to all sub processes

source (program name) => it is used when a child process set values and wants to keep its environment variables inside the parent environment as well.
example
source bash script.sh (with shebang)
_______
for script.sh
#!/bin/bash (shebang)

NAME=Mohammad
_______

alias: it is short name (can be access inside .bashrc) and we can add shortcut for bash.
example:
alias testingping='ping 8.8.8.8' => thus when testingping is type it will ping 8.8.8.8
alias => will list all aliases

functions : can act similar to aliases 
example:
listmystuff (){
ls -ltrh
echo "all your stuff is listed :) "
}


### LPIC-001-051 Different shell envs ###

different between interactive shell and login shell.
when an app or terminal is opened it is actually an interaction with that but its not login shell.
login shell is when you define your username and password to work with that environment
the procedure of checking user profile is like this
1. etc/profile is run
2.a line in etc/profile runs /etc/profile.d/
now the global profile is loaded and system checks for user specifics
3.1 /home/USERNAME/.bash_profile
3.2 /home/USERNAME/.bash_login
3.3 /home/USERNAME/.profile
finally 
4. /home/USERNAME/.bashrc will be run
if environment variable or PATH are going to  be set for that specific user .bashrc in USERNAME can be used to define them
export NAME="username"
export PATH=$PATH:/desiredpath

note: regular ls does not show file with "." in their first name
ls -ltrha should be used
ls -a => shows hidden files in a directory

etc/skel => it contains the template and skeleton of each user. a new created user will use this directory by default

.bash_logout => clears the console after users log out


### LPIC-001-052 customise or write simple script ###
semicolon in command line will cause to execute each line after each other
example:
cd /tmp ; ls  => change directory to /tmp and then list items
_ ; _ ; _ => step by step
cd /tmp && ls => this one is more often used because and stands for if the first command was successful.
_ || _ || _ => this way of commanding is same as using "OR" logic
exmaple:
backup || tar cf => get backup or get tar

shell scripts:
shell files are mostly start with #!/bin/bash (shebang) and are name filename.sh
example:

vi myscript.sh
	ls 
	cd /tmp
	touch $1
	echo "done"

chmod 755 myscript.sh => to give permissions (important) 

./myscript.sh myfile => 
myfile is a parameter and will be placed in code as $1
if another parameter was added, simple by using $2 in code it would be accessible and could be used.

./myscript.sh myfile == bash myscript.sh myfile. however shebang in myscript.sh is the way to not use bash myscript.sh 

vim parametercount.sh
	#!/bin/bash
	echo " number of parameter is equal to $#" => $# shows number of parameters given to the script file.
chmod +x parametercount.sh => gives executable permission

command substitution:
we can give result of a command to a variable in shell
example:
FILES=$(ls) => it will save result of ls in FILES variable
FILES=`ls` => it also do the same but instead we use backtick "`"
for instance:

FILENAME= `date +'%Y-%m-%d - %H:%m'`
bash myscript.sh $FILENAME => result of the touch will be with date name

exec myscript.sh => it executes the file and not like bash (which creates subprocess for that and in the end return to itself) it replaces it environment with itself.

### LPIC-001-053 shell scripting conditions and loops ###

if logic is going to be added to our shell scripting we can use if conditioning.
example:

#!/bin/bash

if [ $# -ne 1 ] (-ne: not equal to, eq: equal to)
then
	echo "file needs exactly 1 parameter
	exit 1
else 
	cd /desktop
	touch `date +'%y-%m-%d-%s'` -$1
	ls -ltrh | tail -5
	echo "done"
	exit 0
fi

exit 0, exit 1, exit 2
in linux script due to its base on C, each function or condition should return something. exit 0 means that program has been run without error. and exit 1 means it had an error
exit 2 for example can mean that it got number instead of string ( it can be defined and be placed in documents)

echo $? => it displays the variable of the last executed program in bash

test condition = [ condition ]

conditions:
"a" = "b"  => if two string are equal (in this case it returns false)
"a" != "b" => string is a not equal to string b
4 -lt 40 => if 4 is lower that 40 (true)
g -gt 15 => if 5 is greater than 15 (false)
5 -ge 5 => if 5 is greater or equal to 5
5 -le 3 => if 5 is lesser or equal to 3
9 -ne 2 => if 9 is not equal to 2 (true)
-f FILENAME => if FILENAME exists
-s FILENAME => if file exists and its size is more than 0
-x FILENAME => if file exists and is executable

to read the user input, " read " can be used:
read NAME => bash will wait to type something then it will give it to $NAME

example in script
#!/bin/bash

echo "what is your name"
read NAME
echo "hello $NAME"

if [ $NAME = "currentUsername" ]
then
	echo "I know this user"
else
	echo "I wish I knew this user"
fi
echo "cya"

practical example:

if read -t 10 -p "Server adddress?" SERVER ( it will wait 10 second for it )
then 
	echo "Connecting to the $SERVER ... "
else
	echo
	echo "Too late!"
fi
_______________________________________


loops
for loops and while loops are used in bash scripting

for syntax:
for NUM in 1 2 3 4 5 6:
do 
	echo $NUM
done

seq => we can use seq to apply sequence numbering in our script
seq 1 3 10 => it will count 1 to 10 and increase in 3 

______________________________________
for NUM in `seq 1 10`:  (for V in {1..10};)
do 
	echo $NUM
done
_____________________________________
for FILENAME in `ls`:
do 
	echo "the name of file is $FILENAME"
done
_____________________________________
using let for mathematic calculation in script

VAR=52

while [ $VAR -gt 42 ]
do 
	echo "VAR is $VAR and it is stil greater than 42"
	let VAR=VAR-1
done
____________________________________


mailing the root user
for sending mail, mailutils needs to be installed. then the mail command will send emails. mail can be sent to the root by this command:

mail root
Cc:
Subject: Hi root its an email
hellooow, this email is just a test

root can read it by using mail command

sending email in script
echo "Body" | mail -s "Subject" root

practical example:
backup.sh || echo "error" | mail -s 'backup error' root => it will prepare a backup and if it fails it will send an email to root or admin

### LPIC-001-054 Install and configuration of X11

after hardware architecture and kernel, the next layer is display server. some programs such as X11, wayland and xorg have duty to process the dsiplay server. after that we have desktop manager(GNOME,KDE,...) and window manager(OpenBox, i3, dwm, awesome) and both are connected to user end.

X window system is a network transparent window system which run on wide range of computing and graphical machines.

Xorg configuration file is not  easily reachable in latest linuxes but by Xorg -configure we can see it's configuration files.

common use for configurating file:
instead of for example, etc/X11/xorg.config/ we can use etc/X11/xorg.config.d/
config.d is a directory for adding new scripts and configuration that will not conflict with updates

error logs go to ~/.xsession-errors

xhost: it controls the access of X server  and can be controlled for clients
example:
xhost +92.168.45.5 => it will give access of xhost to this specific ip

xauth: we display and show the x server depend on special authority signiture
it's file is located in XAuthority

### LPIC-001-055 Graphical Desktop ### 
Login Environments:
when system is booted, after that a graphical Login interfaces appears which is an interface protocol between X and Desktop, and it is called XDMCP (X Displayer manager Control Protocol). other program such as GDM (for Gnome), SSDM (KDE) and XDM handles the theming and other parts of login

Desktop Environments
GNOME: Focuses on productiviy and Accessibility. is used by most of GNU/Linux distros
KDE (Kool Desktop Environment) (Plasma): Highly Customisable, CERN uses KDE
XFCE: Lightweight and Modular

Remote Connection to GUIs

X Forwarding: it is a process of forwarding process of a remote machine to in used machine.
for instance if X11Forwading yes if configured in /etc/ssh/sshd_config and if command of:
$ ssh -X server_ip.address.net
$ xeyes
are commanded then xeyes will be forward to the desktop that is connecting to remote desktop. actually the graphical interface of remote machine will be forwarded to connected desktop

Protocols for remote desktop
VNC (Virtual Network Computer): old. multi-platform and uses RFB protocol. its default port is 5900 and it's not secure.( its password is kept in plaintext for example).
also it is versatile and flexible 

Spice (Simple Protocol for Independent Computing Environment):
KVM machines use this protocol and it has fast speed and low CPU usage.

RDP (Remote Desktop Protocol):
most common Remote Protocol and is used on port 3389 by default. also, the traffic is encrypted by default. it uses softwares like Xrdp.


### LPIC-001-056 106.3 Accessibility ###
Linux is for Everyone.

1.AccessX helps people with Physical problems to use keyboard/mouse. 2.Visual settings help with vision problems by magnifying the screen. 3. assistive technologies are thing like text-to-speech (TTS).


### LPIC-001-057 107.1 Manage user and group accounts and related system files. ### IMPORTANT

Password
command:
passwd => it changes password of the user.
how ever root can change password without any old password request. for example:
sudo passwd (username)

Manage Users
commands:
whoami and who are used for checking users.
useradd (new_username)=> to add new user

important switches are:
-d: home directory (-d /home/user) 
-m: create home directory
-s: specify shell
-G: add to additional groups
-c: to add a comment

adduser => it is similar to useradd but it uses information and ask question about procedure of creating new user.

Modifying users
usermod => modifies users	
usermod -s /bin/csh (username) => it will change default bash for username

swtiches
-L => will lock the user
-U => unlock the user
-aG => add to more groups for example usermod -aG wheel (username)
-G alone will remove all previous groups and add chosen groups instead

userdel -r (username) => to delete user (-r is used to delete home directory too)

Manage Groups
commands:
groupadd, groupdel , groupmod
example:
groupadd -g 1200 newgroup => it will make a new group with id 1200 and name of newgroup

note: in linux OS group and user ids for normal users and groups start from 1000


### LPIC-001-058 107.1 File managing users and groups ###

/etc/passwd => this file contains all the information about users in system

each user can have a primary group and lots of secondary users
in /etc/passwd file, username:x:1002 , the x indicates that the user has a password.

password are kept in /etc/shadow

in /etc/shadow some password are encrypted in such order: 16737:0:99999:7:::
fields and their meaning:
16737: when was the last time this password changes
0: user won't be able to change the password 0 days after each changes
99999: after this many days, the user have to change hus password
7:  user will be informed 7 days before the expiration to change his password

/etc/shadow can only be read by root.

command:
chage (username) => it is used to change password age and pass information of user
chage -l (username) => shows information of user's password

in etc/passwd the ' ! ' sign means that the user is locked

commands:
id (username) => shows information about username
getent [option] (username) => getent is used for getting entry of each user and by using specific option it can be defined which part is needed to be shown from database


### LPIC-001-059 107.2 Automate system administration tasks by scheduling jobs ###

there are cases that a command needs to be scheduled to be executed at certain time so scheduling programs are used to take over such actions

Crontab format: works with a configuration file which tells it when to run a command.

commands:
crontab -l (username - root) => shows scheduled programs for each users
crontab -e => is used to edit crontab 

crontab structure =>
#	M		H		DOM		MON		DOW	 	command
	*/15		1		2			*			1,2,3			/root/backup.sh
	42		3		*			*			0			ls
 
* => it means whenever or all the values. it can be used for when we want to only set the hours or want to set sundays to do scheduling and don't want to specify exact day of month or week.

1,2,3 in DOW => it means to run it on monday, tuesday and wednesday.

*/15 => it means each 15 minutes 
M: minute => values:(0-59)
H: hour => values:(0-23)
DOM: day of the month => values:(1-31)
MON: month => values:(1-12 or names)
DOW: day of week => values:(0-7 0 or 7 is sunday, name also can be used)

note: if inserted values are wrong or have mismatch, cron will throw an error and indicate the problem to be fixed thats why crontab -e is used.

note result of cron is send via email to the defined user
also result can be redirect to not have messy mailbox
by for instance:
$HOME/bin/daily.job >> $HOME/tmp/out 2>&1

crons files for each user are kept in /var/spool/cron/tabs or /var/spool/crontabs

/etc/crontab => it is the file of the crontab and by catting it more information will be shown

system hourly, daily, weekly,... crons
system level crontab files also can be find in /etc/cron.d (tab needed) . general crontabs exist there but they are not much determined as exact timing. note that scripts are placed there and some programs keep their logs or scripts there.

at
at is used to run a command only once for set time.
command:
at now + 1 min 
> touch /tmp/logfilewithAt
(ctrl+D) => to write down the script
=> the command will execute touch command 1 minute after current time.
also in some systems at process is not active in systemctl so 
' systemctl start atd ' needs to be run

atq => will show queue of commands in at
atrm (number) => will remove job of that number 

cron and at access can be defined for users by modifying or creating these files:
/etc/cron.allow 
/etc/cron.deny

/etc/at.allow
/etc/at.deny
